Things that need to be done for an environment that can be used for Q-learning:
1. step function: returns 4 values:
    - observation(object):the state
    - reward(float): the amount of reward achieved by the previous action.
    - done (bool): whether it's time to reset the environment (should be decided based on the schedulability, if not schedulable, then restart)
    - info (dict): diagnostic info useful for debugging. not allowed to use this for learning.


KEY PROBLEM:
1. What should be the task and what should be the partition set?
    Set partition set as fixed for now. Give different task set in and give rewards based on the best fit first; (version 1 in Q-Learning)
2. Put run_model into step mode: one step a time
3. put critical_time and mapping all into the member of the class. Make a step function that takes in the action instead of the scheduler
4. Find a way to export the final result so as to test (some discussions).
