{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ortci\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron (MLP) for multi-class softmax classification:\n",
    "# modified from \n",
    "# https://keras.io/getting-started/sequential-model-guide/#multilayer-perceptron-mlp-for-multi-class-softmax-classification\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_samples = 1000000\n",
    "n_partitions = 10\n",
    "\n",
    "# Generate tasks and partitions\n",
    "partition_data = np.random.random((n_samples, n_partitions)) # partition data generation\n",
    "\n",
    "data = np.zeros((n_samples, n_partitions))                   # initialize input layer\n",
    "labels = np.zeros((n_samples, n_partitions))                 # initialize outputs layer for training \n",
    "fit_data = np.zeros((n_samples, n_partitions))\n",
    "\n",
    "task_data = np.zeros((n_samples, 1))                         # initialize task list\n",
    "\n",
    "# fails to account a 'perfect' fit where fit == 0\n",
    "for i in range (0, n_samples):\n",
    "    \n",
    "    partitions = partition_data[i]\n",
    "    task = random.uniform(0, partitions.max())\n",
    "    task_data[i] = task\n",
    "    \n",
    "    best_partition = -1\n",
    "    best_fit = 999999999\n",
    "    \n",
    "    for j in range (0, n_partitions):\n",
    "        current_fit = partitions[j] - task\n",
    "        data[i,j] = current_fit\n",
    "        if current_fit > 0:\n",
    "            fit_data[i][j] = 1\n",
    "            \n",
    "            if current_fit < best_fit:\n",
    "                best_fit = current_fit\n",
    "                best_partition = j\n",
    "        else:\n",
    "            fit_data[i][j] = 0\n",
    "            \n",
    "    labels[i][best_partition] = 1\n",
    "    \n",
    "\n",
    "X = np.hstack((task_data,partition_data,fit_data))\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data between train and test set \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('MLP_relu_softmax_21_inputs_20_outputs_v1.h5')\n",
    "\n",
    "# Unfreeze all layers in first model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Construct 2nd half model\n",
    "n_nodes = 64\n",
    "model.add(Dense(n_nodes, input_dim=2*n_partitions, activation='relu', name='layerA'))\n",
    "model.add(Dense(n_nodes, activation='relu', name='layerB'))\n",
    "model.add(Dense(n_partitions, activation='softmax', name='softmax'))\n",
    "\n",
    "model.load_weights('simple_classifer_sign_inputs_wts.h5', by_name=True)\n",
    "\n",
    "# optimizer options\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = tf.train.RMSPropOptimizer(0.008)\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output current NN architecture to .png file\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "from keras.models import load_model\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='combined_model_config_21_inputs.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.002),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "800000/800000 [==============================] - 108s 134us/step - loss: 0.6553 - categorical_accuracy: 0.7779\n",
      "Epoch 2/40\n",
      "800000/800000 [==============================] - 108s 135us/step - loss: 0.3719 - categorical_accuracy: 0.8436\n",
      "Epoch 3/40\n",
      "800000/800000 [==============================] - 108s 135us/step - loss: 0.3381 - categorical_accuracy: 0.8573\n",
      "Epoch 4/40\n",
      "800000/800000 [==============================] - 107s 134us/step - loss: 0.3156 - categorical_accuracy: 0.8664\n",
      "Epoch 5/40\n",
      "800000/800000 [==============================] - 108s 135us/step - loss: 0.3036 - categorical_accuracy: 0.8718\n",
      "Epoch 6/40\n",
      "800000/800000 [==============================] - 108s 135us/step - loss: 0.2927 - categorical_accuracy: 0.8765\n",
      "Epoch 7/40\n",
      "800000/800000 [==============================] - 112s 140us/step - loss: 0.2847 - categorical_accuracy: 0.8796\n",
      "Epoch 8/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2782 - categorical_accuracy: 0.8827\n",
      "Epoch 9/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2717 - categorical_accuracy: 0.8850\n",
      "Epoch 10/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2663 - categorical_accuracy: 0.8878\n",
      "Epoch 11/40\n",
      "800000/800000 [==============================] - 112s 140us/step - loss: 0.2626 - categorical_accuracy: 0.8894\n",
      "Epoch 12/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2593 - categorical_accuracy: 0.8905\n",
      "Epoch 13/40\n",
      "800000/800000 [==============================] - 109s 136us/step - loss: 0.2554 - categorical_accuracy: 0.8925\n",
      "Epoch 14/40\n",
      "800000/800000 [==============================] - 112s 140us/step - loss: 0.2535 - categorical_accuracy: 0.8936\n",
      "Epoch 15/40\n",
      "800000/800000 [==============================] - 113s 142us/step - loss: 0.2525 - categorical_accuracy: 0.8938\n",
      "Epoch 16/40\n",
      "800000/800000 [==============================] - 112s 140us/step - loss: 0.2511 - categorical_accuracy: 0.8947\n",
      "Epoch 17/40\n",
      "800000/800000 [==============================] - 113s 142us/step - loss: 0.2494 - categorical_accuracy: 0.8957\n",
      "Epoch 18/40\n",
      "800000/800000 [==============================] - 110s 137us/step - loss: 0.2482 - categorical_accuracy: 0.8961\n",
      "Epoch 19/40\n",
      "800000/800000 [==============================] - 112s 140us/step - loss: 0.2465 - categorical_accuracy: 0.8972\n",
      "Epoch 20/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2467 - categorical_accuracy: 0.8971\n",
      "Epoch 21/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2453 - categorical_accuracy: 0.8977\n",
      "Epoch 22/40\n",
      "800000/800000 [==============================] - 113s 141us/step - loss: 0.2443 - categorical_accuracy: 0.8986\n",
      "Epoch 23/40\n",
      "800000/800000 [==============================] - 110s 138us/step - loss: 0.2427 - categorical_accuracy: 0.8991\n",
      "Epoch 24/40\n",
      "800000/800000 [==============================] - 110s 138us/step - loss: 0.2413 - categorical_accuracy: 0.8995\n",
      "Epoch 25/40\n",
      "800000/800000 [==============================] - 110s 138us/step - loss: 0.2412 - categorical_accuracy: 0.8997\n",
      "Epoch 26/40\n",
      "800000/800000 [==============================] - 111s 138us/step - loss: 0.2397 - categorical_accuracy: 0.9002\n",
      "Epoch 27/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2381 - categorical_accuracy: 0.9011\n",
      "Epoch 28/40\n",
      "800000/800000 [==============================] - 110s 138us/step - loss: 0.2384 - categorical_accuracy: 0.9014\n",
      "Epoch 29/40\n",
      "800000/800000 [==============================] - 111s 138us/step - loss: 0.2376 - categorical_accuracy: 0.9014\n",
      "Epoch 30/40\n",
      "800000/800000 [==============================] - 110s 138us/step - loss: 0.2351 - categorical_accuracy: 0.9028\n",
      "Epoch 31/40\n",
      "800000/800000 [==============================] - 111s 138us/step - loss: 0.2355 - categorical_accuracy: 0.9026\n",
      "Epoch 32/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2354 - categorical_accuracy: 0.9030\n",
      "Epoch 33/40\n",
      "800000/800000 [==============================] - 111s 138us/step - loss: 0.2351 - categorical_accuracy: 0.9030\n",
      "Epoch 34/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2340 - categorical_accuracy: 0.9035\n",
      "Epoch 35/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2343 - categorical_accuracy: 0.9030\n",
      "Epoch 36/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2340 - categorical_accuracy: 0.9034\n",
      "Epoch 37/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2326 - categorical_accuracy: 0.9040\n",
      "Epoch 38/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2326 - categorical_accuracy: 0.9045\n",
      "Epoch 39/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2327 - categorical_accuracy: 0.9043\n",
      "Epoch 40/40\n",
      "800000/800000 [==============================] - 111s 139us/step - loss: 0.2335 - categorical_accuracy: 0.9039\n",
      "200000/200000 [==============================] - 8s 39us/step\n",
      "[0.1573304794025421, 0.934430000038147]\n"
     ]
    }
   ],
   "source": [
    "batchsize = 512\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=40,\n",
    "          batch_size=batchsize)\n",
    "score = model.evaluate(X_test, y_test, batch_size=batchsize)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ortci\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:118: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndel model  # deletes the existing model\\n\\n# returns a compiled model\\n# identical to the previous one\\nmodel = load_model('MLP_Multiclass_softmax_10_inputs.h5')\\nmodel.load_weights('MLP_Multiclass_softmax_10_inputs_weights.h5') # for same architecture\\nmodel.load_weights('MLP_Multiclass_softmax_10_inputs_weights.h5', by_name=True) # for different architecture\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### from keras.models import load_model\n",
    "\n",
    "model.save('combined4b.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "model.save_weights('combined4b_weights.h5')\n",
    "\n",
    "'''\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('MLP_Multiclass_softmax_10_inputs.h5')\n",
    "model.load_weights('MLP_Multiclass_softmax_10_inputs_weights.h5') # for same architecture\n",
    "model.load_weights('MLP_Multiclass_softmax_10_inputs_weights.h5', by_name=True) # for different architecture\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# find cases for misclassification\n",
    "misclass_set = []\n",
    "for i in range(0,100):\n",
    "    if (np.around(y_pred[i],0) != y_test[i]).any():\n",
    "        misclass_set.append(i)\n",
    "num_misclass = len(misclass_set)\n",
    "print(num_misclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Partition_AF</th>\n",
       "      <td>1.456530e-01</td>\n",
       "      <td>0.179568</td>\n",
       "      <td>5.513937e-02</td>\n",
       "      <td>0.797976</td>\n",
       "      <td>0.648353</td>\n",
       "      <td>0.069971</td>\n",
       "      <td>0.610844</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>9.300118e-01</td>\n",
       "      <td>0.801615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task_Size</th>\n",
       "      <td>7.684792e-01</td>\n",
       "      <td>0.768479</td>\n",
       "      <td>7.684792e-01</td>\n",
       "      <td>0.768479</td>\n",
       "      <td>0.768479</td>\n",
       "      <td>0.768479</td>\n",
       "      <td>0.768479</td>\n",
       "      <td>0.768479</td>\n",
       "      <td>7.684792e-01</td>\n",
       "      <td>0.768479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Best_Fit</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_Best_Fit</th>\n",
       "      <td>5.090148e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.937781e-07</td>\n",
       "      <td>0.481394</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>3.148277e-07</td>\n",
       "      <td>0.518534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1             2         3         4  \\\n",
       "Partition_AF     1.456530e-01  0.179568  5.513937e-02  0.797976  0.648353   \n",
       "Task_Size        7.684792e-01  0.768479  7.684792e-01  0.768479  0.768479   \n",
       "Actual_Best_Fit  0.000000e+00  0.000000  0.000000e+00  1.000000  0.000000   \n",
       "Pred_Best_Fit    5.090148e-07  0.000008  4.937781e-07  0.481394  0.000001   \n",
       "\n",
       "                        5         6         7             8         9  \n",
       "Partition_AF     0.069971  0.610844  0.974728  9.300118e-01  0.801615  \n",
       "Task_Size        0.768479  0.768479  0.768479  7.684792e-01  0.768479  \n",
       "Actual_Best_Fit  0.000000  0.000000  0.000000  0.000000e+00  0.000000  \n",
       "Pred_Best_Fit    0.000008  0.000007  0.000047  3.148277e-07  0.518534  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show results of any specific case\n",
    "test = misclass_set[2]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.DataFrame(np.vstack((X_test[test][1:n_partitions+1],\n",
    "                                  np.full((1,10),X_test[test][0]),\n",
    "                                  y_test[test][0:n_partitions],\n",
    "                                  y_pred[test][0:n_partitions])))\n",
    "\n",
    "test_df.index = (\"Partition_AF\",\n",
    "                 \"Task_Size\",\n",
    "                 \"Actual_Best_Fit\", # actual fit\n",
    "                 \"Pred_Best_Fit\")   # actual fit\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
